{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fb0b9fb-03e8-4e91-8302-2e636c641df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/ray/autoscaler/_private/cli_logger.py:57: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import argparse\n",
    "\n",
    "from filelock import FileLock\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import PopulationBasedTraining\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision.datasets import CIFAR10\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import ray\n",
    "from ray.tune import CLIReporter\n",
    "from ray.util.sgd.torch import TorchTrainer, TrainingOperator\n",
    "from ray.util.sgd.torch.resnet import ResNet18\n",
    "from ray.util.sgd.utils import BATCH_SIZE, override"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8d481d6-dba5-4647-bcb6-db9d5e5d22b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialization_hook():\n",
    "    # Need this for avoiding a connection restart issue on AWS.\n",
    "    os.environ[\"NCCL_SOCKET_IFNAME\"] = \"^docker0,lo\"\n",
    "    os.environ[\"NCCL_LL_THRESHOLD\"] = \"0\"\n",
    "\n",
    "    # set the below if needed\n",
    "    # print(\"NCCL DEBUG SET\")\n",
    "    # os.environ[\"NCCL_DEBUG\"] = \"INFO\"\n",
    "\n",
    "\n",
    "class CifarTrainingOperator(TrainingOperator):\n",
    "    @override(TrainingOperator)\n",
    "    def setup(self, config):\n",
    "        # Create model.\n",
    "        model = ResNet18(config)\n",
    "\n",
    "        # Create optimizer.\n",
    "        optimizer = torch.optim.SGD(\n",
    "            model.parameters(),\n",
    "            lr=config.get(\"lr\", 0.1),\n",
    "            momentum=config.get(\"momentum\", 0.9))\n",
    "\n",
    "        # Load in training and validation data.\n",
    "        transform_train = transforms.Compose([\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                                 (0.2023, 0.1994, 0.2010)),\n",
    "        ])  # meanstd transformation\n",
    "\n",
    "        transform_test = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                                 (0.2023, 0.1994, 0.2010)),\n",
    "        ])\n",
    "\n",
    "        with FileLock(\".ray.lock\"):\n",
    "            train_dataset = CIFAR10(\n",
    "                root=\"~/data\",\n",
    "                train=True,\n",
    "                download=True,\n",
    "                transform=transform_train)\n",
    "            validation_dataset = CIFAR10(\n",
    "                root=\"~/data\",\n",
    "                train=False,\n",
    "                download=False,\n",
    "                transform=transform_test)\n",
    "\n",
    "        if config.get(\"test_mode\"):\n",
    "            train_dataset = Subset(train_dataset, list(range(64)))\n",
    "            validation_dataset = Subset(validation_dataset, list(range(64)))\n",
    "\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset, batch_size=config[BATCH_SIZE], num_workers=2)\n",
    "        validation_loader = DataLoader(\n",
    "            validation_dataset, batch_size=config[BATCH_SIZE], num_workers=2)\n",
    "\n",
    "        # Create loss.\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        self.model, self.optimizer, self.criterion = \\\n",
    "            self.register(models=model, optimizers=optimizer,\n",
    "                          criterion=criterion,)\n",
    "        self.register_data(\n",
    "            train_loader=train_loader, validation_loader=validation_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62e408b-59a4-49ed-bde5-19812f87560a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-14 19:00:52,011\tINFO services.py:1267 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
      "2021-06-14 19:00:52,014\tWARNING services.py:1716 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67108864 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=4.07gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2021-06-14 19:00:53,617\tERROR syncer.py:72 -- Log sync requires rsync to be installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 3.3/30.6 GiB\n",
      "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
      "Resources requested: 2.0/4 CPUs, 0/0 GPUs, 0.0/7.4 GiB heap, 0.0/3.7 GiB objects\n",
      "Result logdir: /home/ubuntu/ray_results/TorchTrainable_2021-06-14_19-00-53\n",
      "Number of trials: 4/4 (3 PENDING, 1 RUNNING)\n",
      "+----------------------------+----------+-------+------+\n",
      "| Trial name                 | status   | loc   |   lr |\n",
      "|----------------------------+----------+-------+------|\n",
      "| TorchTrainable_d7a9a_00000 | RUNNING  |       | 0.01 |\n",
      "| TorchTrainable_d7a9a_00001 | PENDING  |       | 0.1  |\n",
      "| TorchTrainable_d7a9a_00002 | PENDING  |       | 0.01 |\n",
      "| TorchTrainable_d7a9a_00003 | PENDING  |       | 0.01 |\n",
      "+----------------------------+----------+-------+------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2765)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(pid=2764)\u001b[0m Files already downloaded and verified\n",
      "== Status ==\n",
      "Memory usage on this node: 5.4/30.6 GiB\n",
      "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
      "Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/7.4 GiB heap, 0.0/3.7 GiB objects\n",
      "Result logdir: /home/ubuntu/ray_results/TorchTrainable_2021-06-14_19-00-53\n",
      "Number of trials: 4/4 (2 PENDING, 2 RUNNING)\n",
      "+----------------------------+----------+-------+------+\n",
      "| Trial name                 | status   | loc   |   lr |\n",
      "|----------------------------+----------+-------+------|\n",
      "| TorchTrainable_d7a9a_00000 | RUNNING  |       | 0.01 |\n",
      "| TorchTrainable_d7a9a_00001 | RUNNING  |       | 0.1  |\n",
      "| TorchTrainable_d7a9a_00002 | PENDING  |       | 0.01 |\n",
      "| TorchTrainable_d7a9a_00003 | PENDING  |       | 0.01 |\n",
      "+----------------------------+----------+-------+------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-14 19:07:04,708\tWARNING tune.py:506 -- SIGINT received (e.g. via Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C one more time (or send SIGINT/SIGKILL/SIGTERM) to skip. \n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--address\",\n",
    "        required=False,\n",
    "        type=str,\n",
    "        help=\"the address to use for Redis\")\n",
    "    parser.add_argument(\n",
    "        \"--server-address\",\n",
    "        type=str,\n",
    "        default=None,\n",
    "        required=False,\n",
    "        help=\"The address of server to connect to if using \"\n",
    "        \"Ray Client.\")\n",
    "    parser.add_argument(\n",
    "        \"--num-workers\",\n",
    "        \"-n\",\n",
    "        type=int,\n",
    "        default=1,\n",
    "        help=\"Sets number of workers for training.\")\n",
    "    parser.add_argument(\n",
    "        \"--num-epochs\", type=int, default=5, help=\"Number of epochs to train.\")\n",
    "    parser.add_argument(\n",
    "        \"--use-gpu\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "        help=\"Enables GPU training\")\n",
    "    parser.add_argument(\n",
    "        \"--fp16\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "        help=\"Enables FP16 training with apex. Requires `use-gpu`.\")\n",
    "    parser.add_argument(\n",
    "        \"--smoke-test\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "        help=\"Finish quickly for testing.\")\n",
    "    parser.add_argument(\n",
    "        \"--tune\", action=\"store_true\", default=False, help=\"Tune training\")\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "    if args.server_address:\n",
    "        print(\"Connecting to Ray cluster...\")\n",
    "        service_host = os.environ[\"RAY_HEAD_SERVICE_HOST\"]\n",
    "        service_port = os.environ[\"RAY_HEAD_SERVICE_PORT\"]\n",
    "        ray.util.connect(f\"{service_host}:{service_port}\")\n",
    "    else:\n",
    "        ray.init(address=args.address, log_to_driver=True)\n",
    "\n",
    "    TorchTrainable = TorchTrainer.as_trainable(\n",
    "        training_operator_cls=CifarTrainingOperator,\n",
    "        initialization_hook=initialization_hook,\n",
    "        num_workers=args.num_workers,\n",
    "        config={\n",
    "            \"test_mode\": args.smoke_test,  # whether to to subset the data\n",
    "            BATCH_SIZE: 128 * args.num_workers,\n",
    "        },\n",
    "        use_gpu=args.use_gpu,\n",
    "        use_fp16=args.fp16)\n",
    "\n",
    "    pbt_scheduler = PopulationBasedTraining(\n",
    "        time_attr=\"training_iteration\",\n",
    "        metric=\"val_loss\",\n",
    "        mode=\"min\",\n",
    "        perturbation_interval=1,\n",
    "        hyperparam_mutations={\n",
    "            # distribution for resampling\n",
    "            \"lr\": lambda: np.random.uniform(0.001, 1),\n",
    "            # allow perturbations within this set of categorical values\n",
    "            \"momentum\": [0.8, 0.9, 0.99],\n",
    "        })\n",
    "\n",
    "    reporter = CLIReporter()\n",
    "    reporter.add_metric_column(\"val_loss\", \"loss\")\n",
    "    reporter.add_metric_column(\"val_accuracy\", \"acc\")\n",
    "\n",
    "    analysis = tune.run(\n",
    "        TorchTrainable,\n",
    "        num_samples=4,\n",
    "        config={\n",
    "            \"lr\": tune.choice([0.001, 0.01, 0.1]),\n",
    "            \"momentum\": 0.8\n",
    "        },\n",
    "        stop={\"training_iteration\": 2 if args.smoke_test else 100},\n",
    "        max_failures=3,  # used for fault tolerance\n",
    "        checkpoint_freq=3,  # used for fault tolerance\n",
    "        keep_checkpoints_num=1,  # used for fault tolerance\n",
    "        verbose=2,\n",
    "        progress_reporter=reporter,\n",
    "        scheduler=pbt_scheduler)\n",
    "\n",
    "    print(analysis.get_best_config(metric=\"val_loss\", mode=\"min\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
