{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "934d1d89-2319-48fc-b6e1-f6a51f6ef014",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import argparse\n",
    "\n",
    "from filelock import FileLock\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision.datasets import CIFAR10\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from tqdm import trange\n",
    "\n",
    "import ray\n",
    "from ray.util.sgd.torch import TorchTrainer, TrainingOperator\n",
    "from ray.util.sgd.torch.resnet import ResNet18\n",
    "from ray.util.sgd.utils import BATCH_SIZE, override"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eeb4581b-aab1-474c-8331-c8b4cffc5612",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialization_hook():\n",
    "    # Need this for avoiding a connection restart issue on AWS.\n",
    "    os.environ[\"NCCL_SOCKET_IFNAME\"] = \"^docker0,lo\"\n",
    "    os.environ[\"NCCL_LL_THRESHOLD\"] = \"0\"\n",
    "\n",
    "    # set the below if needed\n",
    "    # print(\"NCCL DEBUG SET\")\n",
    "    # os.environ[\"NCCL_DEBUG\"] = \"INFO\"\n",
    "\n",
    "\n",
    "class CifarTrainingOperator(TrainingOperator):\n",
    "    @override(TrainingOperator)\n",
    "    def setup(self, config):\n",
    "        # Create model.\n",
    "        model = ResNet18(config)\n",
    "\n",
    "        # Create optimizer.\n",
    "        optimizer = torch.optim.SGD(\n",
    "            model.parameters(),\n",
    "            lr=config.get(\"lr\", 0.1),\n",
    "            momentum=config.get(\"momentum\", 0.9))\n",
    "\n",
    "        # Load in training and validation data.\n",
    "        transform_train = transforms.Compose([\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                                 (0.2023, 0.1994, 0.2010)),\n",
    "        ])  # meanstd transformation\n",
    "\n",
    "        transform_test = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                                 (0.2023, 0.1994, 0.2010)),\n",
    "        ])\n",
    "        with FileLock(\".ray.lock\"):\n",
    "            train_dataset = CIFAR10(\n",
    "                root=\"~/data\",\n",
    "                train=True,\n",
    "                download=True,\n",
    "                transform=transform_train)\n",
    "            validation_dataset = CIFAR10(\n",
    "                root=\"~/data\",\n",
    "                train=False,\n",
    "                download=False,\n",
    "                transform=transform_test)\n",
    "\n",
    "        if config[\"test_mode\"]:\n",
    "            train_dataset = Subset(train_dataset, list(range(64)))\n",
    "            validation_dataset = Subset(validation_dataset, list(range(64)))\n",
    "\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset, batch_size=config[BATCH_SIZE], num_workers=2)\n",
    "        validation_loader = DataLoader(\n",
    "            validation_dataset, batch_size=config[BATCH_SIZE], num_workers=2)\n",
    "\n",
    "        # Create scheduler.\n",
    "        scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "            optimizer, milestones=[150, 250, 350], gamma=0.1)\n",
    "\n",
    "        # Create loss.\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Register all components.\n",
    "        self.model, self.optimizer, self.criterion, self.scheduler = \\\n",
    "            self.register(models=model, optimizers=optimizer,\n",
    "                          criterion=criterion, schedulers=scheduler)\n",
    "        self.register_data(\n",
    "            train_loader=train_loader, validation_loader=validation_loader)\n",
    "\n",
    "\n",
    "def train_cifar(test_mode=False,\n",
    "                num_workers=1,\n",
    "                use_gpu=False,\n",
    "                num_epochs=5,\n",
    "                fp16=False):\n",
    "    trainer1 = TorchTrainer(\n",
    "        training_operator_cls=CifarTrainingOperator,\n",
    "        initialization_hook=initialization_hook,\n",
    "        num_workers=num_workers,\n",
    "        config={\n",
    "            \"lr\": 0.1,\n",
    "            \"test_mode\": test_mode,  # subset the data\n",
    "            # this will be split across workers.\n",
    "            BATCH_SIZE: 128 * num_workers\n",
    "        },\n",
    "        use_gpu=use_gpu,\n",
    "        scheduler_step_freq=\"epoch\",\n",
    "        use_fp16=fp16,\n",
    "        use_tqdm=False)\n",
    "    pbar = trange(num_epochs, unit=\"epoch\")\n",
    "    for i in pbar:\n",
    "        info = {\"num_steps\": 1} if test_mode else {}\n",
    "        info[\"epoch_idx\"] = i\n",
    "        info[\"num_epochs\"] = num_epochs\n",
    "        # Increase `max_retries` to turn on fault tolerance.\n",
    "        trainer1.train(max_retries=1, info=info)\n",
    "        val_stats = trainer1.validate()\n",
    "        pbar.set_postfix(dict(acc=val_stats[\"val_accuracy\"]))\n",
    "\n",
    "    print(trainer1.validate())\n",
    "    trainer1.shutdown()\n",
    "    print(\"success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4db63d42-ad5b-4029-a312-7aed753e02fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "RayTaskError(PermissionError)",
     "evalue": "\u001b[36mray::TorchRunner.setup_operator()\u001b[39m (pid=635, ip=100.96.19.6)\n  File \"python/ray/_raylet.pyx\", line 505, in ray._raylet.execute_task\n  File \"python/ray/_raylet.pyx\", line 449, in ray._raylet.execute_task.function_executor\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 556, in actor_method_executor\n    return method(__ray_actor, *args, **kwargs)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/util/sgd/torch/torch_runner.py\", line 57, in setup_operator\n    self.training_operator = self.training_operator_cls(\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/util/sgd/torch/training_operator.py\", line 148, in __init__\n    self.setup(config)\n  File \"<ipython-input-5-86a03cc9cb7f>\", line 37, in setup\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/filelock.py\", line 323, in __enter__\n    self.acquire()\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/filelock.py\", line 271, in acquire\n    self._acquire()\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/filelock.py\", line 384, in _acquire\n    fd = os.open(self._lock_file, open_mode)\nPermissionError: [Errno 13] Permission denied: '.ray.lock'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRayTaskError(PermissionError)\u001b[0m             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-8d0fc73aea3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;31m#         ray.init(address=args.address, num_cpus=num_cpus, log_to_driver=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     train_cifar(test_mode=args.smoke_test,\n\u001b[0m\u001b[1;32m     56\u001b[0m                 \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0muse_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-86a03cc9cb7f>\u001b[0m in \u001b[0;36mtrain_cifar\u001b[0;34m(test_mode, num_workers, use_gpu, num_epochs, fp16)\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                 fp16=False):\n\u001b[0;32m---> 78\u001b[0;31m     trainer1 = TorchTrainer(\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0mtraining_operator_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCifarTrainingOperator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0minitialization_hook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitialization_hook\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ray/util/sgd/torch/torch_trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, training_operator_cls, initialization_hook, config, num_workers, num_cpus_per_worker, use_gpu, backend, wrap_ddp, timeout_s, use_fp16, use_tqdm, add_dist_sampler, scheduler_step_freq, use_local, num_replicas, batch_size, model_creator, data_creator, optimizer_creator, scheduler_creator, loss_creator, serialize_data_creation, data_loader_args, apex_args)\u001b[0m\n\u001b[1;32m    263\u001b[0m                         \"address='auto')` before instantiating the Trainer.\")\n\u001b[1;32m    264\u001b[0m             \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0mstartup_success\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_workers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_replicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstartup_success\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m             raise RuntimeError(\"Worker startup failed. \"\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ray/util/sgd/torch/torch_trainer.py\u001b[0m in \u001b[0;36m_start_workers\u001b[0;34m(self, num_workers)\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;31m#  start_workers should take into account available resources when\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;31m#  determining how many workers to create.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworker_group\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_workers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_resize_worker_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_retries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ray/util/sgd/torch/worker_group.py\u001b[0m in \u001b[0;36mstart_workers\u001b[0;34m(self, num_workers)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     num_gpus=int(self._use_gpu))(TorchRunner)\n\u001b[1;32m    215\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremote_workers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mRemoteRunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                 \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremote_workers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_operator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_dist_workers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclient_mode_should_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ray/util/client/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, vals, timeout)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmilliseconds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \"\"\"\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ray/util/client/worker.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, vals, timeout)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                         \u001b[0mop_timeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMAX_BLOCKING_OPERATION_TIME_S\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mGetTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ray/util/client/worker.py\u001b[0m in \u001b[0;36m_get\u001b[0;34m(self, ref, timeout)\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Failed to deserialize {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloads_from_server\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRayTaskError(PermissionError)\u001b[0m: \u001b[36mray::TorchRunner.setup_operator()\u001b[39m (pid=635, ip=100.96.19.6)\n  File \"python/ray/_raylet.pyx\", line 505, in ray._raylet.execute_task\n  File \"python/ray/_raylet.pyx\", line 449, in ray._raylet.execute_task.function_executor\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 556, in actor_method_executor\n    return method(__ray_actor, *args, **kwargs)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/util/sgd/torch/torch_runner.py\", line 57, in setup_operator\n    self.training_operator = self.training_operator_cls(\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/util/sgd/torch/training_operator.py\", line 148, in __init__\n    self.setup(config)\n  File \"<ipython-input-5-86a03cc9cb7f>\", line 37, in setup\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/filelock.py\", line 323, in __enter__\n    self.acquire()\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/filelock.py\", line 271, in acquire\n    self._acquire()\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/filelock.py\", line 384, in _acquire\n    fd = os.open(self._lock_file, open_mode)\nPermissionError: [Errno 13] Permission denied: '.ray.lock'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--address\",\n",
    "        required=False,\n",
    "        type=str,\n",
    "        help=\"the address to use for connecting to the Ray cluster\")\n",
    "    parser.add_argument(\n",
    "        \"--server-address\",\n",
    "        type=str,\n",
    "        default=None,\n",
    "        required=False,\n",
    "        help=\"The address of server to connect to if using \"\n",
    "        \"Ray Client.\")\n",
    "    parser.add_argument(\n",
    "        \"--num-workers\",\n",
    "        \"-n\",\n",
    "        type=int,\n",
    "        default=1,\n",
    "        help=\"Sets number of workers for training.\")\n",
    "    parser.add_argument(\n",
    "        \"--num-epochs\", type=int, default=5, help=\"Number of epochs to train.\")\n",
    "    parser.add_argument(\n",
    "        \"--use-gpu\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "        help=\"Enables GPU training\")\n",
    "    parser.add_argument(\n",
    "        \"--fp16\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "        help=\"Enables FP16 training with apex. Requires `use-gpu`.\")\n",
    "    parser.add_argument(\n",
    "        \"--smoke-test\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "        help=\"Finish quickly for testing.\")\n",
    "    parser.add_argument(\n",
    "        \"--tune\", action=\"store_true\", default=False, help=\"Tune training\")\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "    if ray.is_initialized() == False:\n",
    "        print(\"Connecting to Ray cluster...\")\n",
    "        service_host = os.environ[\"RAY_HEAD_SERVICE_HOST\"]\n",
    "        service_port = os.environ[\"RAY_HEAD_SERVICE_PORT\"]\n",
    "        ray.util.connect(f\"{service_host}:{service_port}\")\n",
    "#     breakpoint()\n",
    "        \n",
    "#     if args.server_address:\n",
    "#         ray.util.connect(args.server_address)\n",
    "#     else:\n",
    "#         num_cpus = 4 if args.smoke_test else None\n",
    "#         ray.init(address=args.address, num_cpus=num_cpus, log_to_driver=True)\n",
    "\n",
    "    train_cifar(test_mode=args.smoke_test,\n",
    "                num_workers=args.num_workers,\n",
    "                use_gpu=args.use_gpu,\n",
    "                num_epochs=args.num_epochs,\n",
    "                fp16=args.fp16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e542ca20-e6e9-4107-8637-0f5682e68ae2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
