{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "126d7d12-d188-45bc-919c-4074c4fb14ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from ray.air import Checkpoint\n",
    "from ray.train.torch import TorchTrainer\n",
    "from ray.air.config import ScalingConfig\n",
    "import ray.train as train\n",
    "from ray.air import session\n",
    "import argparse\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a82cc322-845e-4832-ae84-b7fb91356255",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "def train_epoch(dataloader, model, loss_fn, optimizer, device='cuda'):\n",
    "    size = len(dataloader.dataset) // session.get_world_size()  # Divide by word size\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # We don't need this anymore! Ray Train does this automatically:\n",
    "        X, y = X.to(device), y.to(device)  \n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            # print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test_epoch(dataloader, model, loss_fn, device='cuda'):\n",
    "    size = len(dataloader.dataset) // session.get_world_size()  # Divide by word size\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    # print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return test_loss\n",
    "\n",
    "def load_data():\n",
    "    # Download training data from open datasets.\n",
    "    training_data = datasets.FashionMNIST(\n",
    "        root=\"data\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=ToTensor(),\n",
    "    )\n",
    "\n",
    "    # Download test data from open datasets.\n",
    "    test_data = datasets.FashionMNIST(\n",
    "        root=\"data\",\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=ToTensor(),\n",
    "    )\n",
    "    return training_data, test_data\n",
    "\n",
    "\n",
    "def train_func(config: dict):\n",
    "    batch_size = config[\"batch_size\"]\n",
    "    lr = config[\"lr\"]\n",
    "    epochs = config[\"epochs\"]\n",
    "    \n",
    "    batch_size_per_worker = batch_size // session.get_world_size()\n",
    "    \n",
    "    training_data, test_data = load_data()  # <- this is new!\n",
    "    \n",
    "    # Create data loaders.\n",
    "    train_dataloader = DataLoader(training_data, batch_size=batch_size_per_worker)\n",
    "    test_dataloader = DataLoader(test_data, batch_size=batch_size_per_worker)\n",
    "    \n",
    "    train_dataloader = train.torch.prepare_data_loader(train_dataloader)\n",
    "    test_dataloader = train.torch.prepare_data_loader(test_dataloader)\n",
    "    \n",
    "    model = NeuralNetwork()\n",
    "    model = train.torch.prepare_model(model)\n",
    "    \n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    \n",
    "    for t in range(epochs):\n",
    "        train_epoch(train_dataloader, model, loss_fn, optimizer)\n",
    "        test_loss = test_epoch(test_dataloader, model, loss_fn)\n",
    "        checkpoint = Checkpoint.from_dict(\n",
    "            dict(epoch=t, model=model.state_dict())\n",
    "        )\n",
    "        session.report(dict(loss=test_loss), checkpoint=checkpoint)\n",
    "\n",
    "    print(\"Done!\")\n",
    "\n",
    "def train_fashion_mnist(num_workers=3, use_gpu=True):\n",
    "    trainer = TorchTrainer(\n",
    "        train_loop_per_worker=train_func,\n",
    "        train_loop_config={\"lr\": 1e-3, \"batch_size\": 64, \"epochs\": 4},\n",
    "        scaling_config=ScalingConfig(num_workers=num_workers, use_gpu=use_gpu),\n",
    "    )\n",
    "    result = trainer.fit()\n",
    "    print(f\"Last result: {result.metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a658ebb9-aa7d-4e1b-bea3-1ed9dacede28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to Ray cluster...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in data channel:\n",
      "Queue filler thread failed to join before timeout: 10\n",
      "2023-04-05 22:41:16,473\tERROR dataclient.py:323 -- Unrecoverable error in data channel.\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "Failed during this or a previous request. Exception that broke the connection: <_MultiThreadedRendezvous of RPC that terminated with:\n\tstatus = StatusCode.FAILED_PRECONDITION\n\tdetails = \"No module named 'IPython'\"\n\tdebug_error_string = \"{\"created\":\"@1680734476.473590501\",\"description\":\"Error received from peer ipv4:172.20.64.229:10001\",\"file\":\"src/core/lib/surface/call.cc\",\"file_line\":1074,\"grpc_message\":\"No module named 'IPython'\",\"grpc_status\":9}\"\n>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m     ray\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mconnect(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mservice_host\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mservice_port\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# train_fashion_mnist(num_workers=args.num_workers, use_gpu=True)\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[43mtrain_fashion_mnist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_gpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 113\u001b[0m, in \u001b[0;36mtrain_fashion_mnist\u001b[0;34m(num_workers, use_gpu)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_fashion_mnist\u001b[39m(num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, use_gpu\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    108\u001b[0m     trainer \u001b[38;5;241m=\u001b[39m TorchTrainer(\n\u001b[1;32m    109\u001b[0m         train_loop_per_worker\u001b[38;5;241m=\u001b[39mtrain_func,\n\u001b[1;32m    110\u001b[0m         train_loop_config\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1e-3\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m64\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m4\u001b[39m},\n\u001b[1;32m    111\u001b[0m         scaling_config\u001b[38;5;241m=\u001b[39mScalingConfig(num_workers\u001b[38;5;241m=\u001b[39mnum_workers, use_gpu\u001b[38;5;241m=\u001b[39muse_gpu),\n\u001b[1;32m    112\u001b[0m     )\n\u001b[0;32m--> 113\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLast result: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/ray/train/base_trainer.py:363\u001b[0m, in \u001b[0;36mBaseTrainer.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    358\u001b[0m param_space \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extract_fields_for_tuner_param_space()\n\u001b[1;32m    360\u001b[0m tuner \u001b[38;5;241m=\u001b[39m Tuner(\n\u001b[1;32m    361\u001b[0m     trainable\u001b[38;5;241m=\u001b[39mtrainable, param_space\u001b[38;5;241m=\u001b[39mparam_space, run_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_config\n\u001b[1;32m    362\u001b[0m )\n\u001b[0;32m--> 363\u001b[0m result_grid \u001b[38;5;241m=\u001b[39m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(result_grid) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/ray/tune/tuner.py:306\u001b[0m, in \u001b[0;36mTuner.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    300\u001b[0m     experiment_checkpoint_dir \u001b[38;5;241m=\u001b[39m ray\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    301\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_remote_tuner\u001b[38;5;241m.\u001b[39mget_experiment_checkpoint_dir\u001b[38;5;241m.\u001b[39mremote()\n\u001b[1;32m    302\u001b[0m     )\n\u001b[1;32m    303\u001b[0m     (\n\u001b[1;32m    304\u001b[0m         progress_reporter,\n\u001b[1;32m    305\u001b[0m         string_queue,\n\u001b[0;32m--> 306\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_remote_tuner_for_jupyter_progress_reporting\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    308\u001b[0m         fit_future \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_remote_tuner\u001b[38;5;241m.\u001b[39mfit\u001b[38;5;241m.\u001b[39mremote()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/ray/tune/tuner.py:261\u001b[0m, in \u001b[0;36mTuner._prepare_remote_tuner_for_jupyter_progress_reporting\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m progress_reporter, string_queue \u001b[38;5;241m=\u001b[39m _prepare_progress_reporter_for_ray_client(\n\u001b[1;32m    258\u001b[0m     run_config\u001b[38;5;241m.\u001b[39mprogress_reporter, run_config\u001b[38;5;241m.\u001b[39mverbose\n\u001b[1;32m    259\u001b[0m )\n\u001b[1;32m    260\u001b[0m run_config\u001b[38;5;241m.\u001b[39mprogress_reporter \u001b[38;5;241m=\u001b[39m progress_reporter\n\u001b[0;32m--> 261\u001b[0m \u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_remote_tuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_run_config_and_remote_string_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremote\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstring_queue\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m progress_reporter, string_queue\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/ray/_private/client_mode_hook.py:104\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m client_mode_should_convert(auto_init\u001b[38;5;241m=\u001b[39mauto_init):\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;66;03m# Legacy code\u001b[39;00m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;66;03m# we only convert init function if RAY_CLIENT_MODE=1\u001b[39;00m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[0;32m--> 104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/ray/util/client/api.py:42\u001b[0m, in \u001b[0;36m_ClientAPI.get\u001b[0;34m(self, vals, timeout)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, vals, \u001b[38;5;241m*\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     36\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"get is the hook stub passed on to replace `ray.get`\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03m        vals: [Client]ObjectRef or list of these refs to retrieve.\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m        timeout: Optional timeout in milliseconds\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/ray/util/client/worker.py:434\u001b[0m, in \u001b[0;36mWorker.get\u001b[0;34m(self, vals, timeout)\u001b[0m\n\u001b[1;32m    432\u001b[0m     op_timeout \u001b[38;5;241m=\u001b[39m max_blocking_operation_time\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 434\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_get\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GetTimeoutError:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/ray/util/client/worker.py:451\u001b[0m, in \u001b[0;36mWorker._get\u001b[0;34m(self, ref, timeout)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get\u001b[39m(\u001b[38;5;28mself\u001b[39m, ref: List[ClientObjectRef], timeout: \u001b[38;5;28mfloat\u001b[39m):\n\u001b[0;32m--> 451\u001b[0m     req \u001b[38;5;241m=\u001b[39m ray_client_pb2\u001b[38;5;241m.\u001b[39mGetRequest(ids\u001b[38;5;241m=\u001b[39m[r\u001b[38;5;241m.\u001b[39mid \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m ref], timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    452\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytearray\u001b[39m()\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/ray/util/client/worker.py:451\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get\u001b[39m(\u001b[38;5;28mself\u001b[39m, ref: List[ClientObjectRef], timeout: \u001b[38;5;28mfloat\u001b[39m):\n\u001b[0;32m--> 451\u001b[0m     req \u001b[38;5;241m=\u001b[39m ray_client_pb2\u001b[38;5;241m.\u001b[39mGetRequest(ids\u001b[38;5;241m=\u001b[39m[\u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m ref], timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    452\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytearray\u001b[39m()\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/ray/util/client/common.py:136\u001b[0m, in \u001b[0;36mClientObjectRef.id\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mid\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/ray/util/client/common.py:115\u001b[0m, in \u001b[0;36mClientObjectRef.binary\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbinary\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mbinary()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/ray/util/client/common.py:192\u001b[0m, in \u001b[0;36mClientObjectRef._wait_for_id\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mutex:\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id_future:\n\u001b[0;32m--> 192\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_id(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_id_future\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    193\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id_future \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/concurrent/futures/_base.py:445\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 445\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/concurrent/futures/_base.py:390\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 390\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    392\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    393\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mConnectionError\u001b[0m: Failed during this or a previous request. Exception that broke the connection: <_MultiThreadedRendezvous of RPC that terminated with:\n\tstatus = StatusCode.FAILED_PRECONDITION\n\tdetails = \"No module named 'IPython'\"\n\tdebug_error_string = \"{\"created\":\"@1680734476.473590501\",\"description\":\"Error received from peer ipv4:172.20.64.229:10001\",\"file\":\"src/core/lib/surface/call.cc\",\"file_line\":1074,\"grpc_message\":\"No module named 'IPython'\",\"grpc_status\":9}\"\n>"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--num-workers\",\"-n\", type=int, default=3, help=\"Sets number of workers for training.\",)\n",
    "    parser.add_argument(\"--use-gpu\", action=\"store_true\", default=True, help=\"Enables GPU training\")\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    import ray\n",
    "    if ray.is_initialized() == False:\n",
    "        print(\"Connecting to Ray cluster...\")\n",
    "        service_host = os.environ[\"RAY_HEAD_SERVICE_HOST\"]\n",
    "        service_port = os.environ[\"RAY_HEAD_SERVICE_PORT\"]\n",
    "        ray.util.connect(f\"{service_host}:{service_port}\")\n",
    "\n",
    "    # train_fashion_mnist(num_workers=args.num_workers, use_gpu=True)\n",
    "    train_fashion_mnist(num_workers=3, use_gpu=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2135aa9a-9611-42e3-9c95-4fed398ecba9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 22:47:31,603\tERROR services.py:1169 -- Failed to start the dashboard \n",
      "2023-04-05 22:47:31,605\tERROR services.py:1194 -- Error should be written to 'dashboard.log' or 'dashboard.err'. We are printing the last 20 lines for you. See 'https://docs.ray.io/en/master/ray-observability/ray-logging.html#logging-directory-structure' to find where the log file is.\n",
      "2023-04-05 22:47:31,606\tERROR services.py:1238 -- \n",
      "The last 20 lines of /tmp/ray/session_2023-04-05_22-47-10_034990_451/logs/dashboard.log (it contains the error message from the dashboard): \n",
      "2023-04-05 22:47:12,088\tINFO http_server_head.py:210 -- <ResourceRoute [GET] <PlainResource  /api/v0/cluster_events> -> <function RateLimitedModule.enforce_max_concurrent_calls.<locals>.async_wrapper at 0x7fe27a657700>\n",
      "2023-04-05 22:47:12,088\tINFO http_server_head.py:210 -- <ResourceRoute [GET] <PlainResource  /api/v0/logs> -> <function RateLimitedModule.enforce_max_concurrent_calls.<locals>.async_wrapper at 0x7fe27a6578b0>\n",
      "2023-04-05 22:47:12,088\tINFO http_server_head.py:210 -- <ResourceRoute [GET] <DynamicResource  /api/v0/logs/{media_type}> -> <function RateLimitedModule.enforce_max_concurrent_calls.<locals>.async_wrapper at 0x7fe27a657a60>\n",
      "2023-04-05 22:47:12,088\tINFO http_server_head.py:210 -- <ResourceRoute [GET] <PlainResource  /api/v0/tasks/summarize> -> <function RateLimitedModule.enforce_max_concurrent_calls.<locals>.async_wrapper at 0x7fe27a657ca0>\n",
      "2023-04-05 22:47:12,088\tINFO http_server_head.py:210 -- <ResourceRoute [GET] <PlainResource  /api/v0/actors/summarize> -> <function RateLimitedModule.enforce_max_concurrent_calls.<locals>.async_wrapper at 0x7fe27a657e50>\n",
      "2023-04-05 22:47:12,088\tINFO http_server_head.py:210 -- <ResourceRoute [GET] <PlainResource  /api/v0/objects/summarize> -> <function RateLimitedModule.enforce_max_concurrent_calls.<locals>.async_wrapper at 0x7fe27a65c040>\n",
      "2023-04-05 22:47:12,088\tINFO http_server_head.py:210 -- <ResourceRoute [GET] <PlainResource  /api/v0/tasks/timeline> -> <function RateLimitedModule.enforce_max_concurrent_calls.<locals>.async_wrapper at 0x7fe27a65c1f0>\n",
      "2023-04-05 22:47:12,088\tINFO http_server_head.py:210 -- <ResourceRoute [GET] <DynamicResource  /api/v0/delay/{delay_s}> -> <function StateHead.delayed_response at 0x7fe27a65c310>\n",
      "2023-04-05 22:47:12,088\tINFO http_server_head.py:210 -- <ResourceRoute [GET] <PlainResource  /usage_stats_enabled> -> <function UsageStatsHead.get_usage_stats_enabled at 0x7fe27a66d280>\n",
      "2023-04-05 22:47:12,088\tINFO http_server_head.py:210 -- <ResourceRoute [GET] <StaticResource  /logs -> PosixPath('/tmp/ray/session_2023-04-05_22-47-10_034990_451/logs')> -> <bound method StaticResource._handle of <StaticResource  /logs -> PosixPath('/tmp/ray/session_2023-04-05_22-47-10_034990_451/logs')>>\n",
      "2023-04-05 22:47:12,088\tINFO http_server_head.py:210 -- <ResourceRoute [GET] <PlainResource  /> -> <function HttpServerDashboardHead.get_index at 0x7fe27a66da60>\n",
      "2023-04-05 22:47:12,088\tINFO http_server_head.py:210 -- <ResourceRoute [GET] <PlainResource  /favicon.ico> -> <function HttpServerDashboardHead.get_favicon at 0x7fe27a66db80>\n",
      "2023-04-05 22:47:12,089\tINFO http_server_head.py:210 -- <ResourceRoute [GET] <StaticResource  /static -> PosixPath('/home/ubuntu/.local/lib/python3.9/site-packages/ray/dashboard/client/build/static')> -> <bound method StaticResource._handle of <StaticResource  /static -> PosixPath('/home/ubuntu/.local/lib/python3.9/site-packages/ray/dashboard/client/build/static')>>\n",
      "2023-04-05 22:47:12,089\tINFO http_server_head.py:211 -- Registered 51 routes.\n",
      "2023-04-05 22:47:12,091\tINFO event_utils.py:132 -- Monitor events logs modified after 1680733031.9979472 on /tmp/ray/session_2023-04-05_22-47-10_034990_451/logs/events, the source types are all.\n",
      "2023-04-05 22:47:12,099\tINFO usage_stats_head.py:168 -- Usage reporting is disabled.\n",
      "2023-04-05 22:47:12,099\tINFO actor_head.py:101 -- Getting all actor info from GCS.\n",
      "2023-04-05 22:47:12,104\tINFO actor_head.py:123 -- Received 0 actor info from GCS.\n",
      "2023-04-05 22:47:22,073\tWARNING node_head.py:221 -- Head node is not registered even after 10 seconds. The API server might not work correctly. Please report a Github issue. Internal states :{'head_node_registration_time_s': None, 'registered_nodes': 0, 'registered_agents': 0, 'node_update_count': 100, 'module_lifetime_s': 9.991142749786377}\n",
      "2023-04-05 22:47:31,608\tWARNING services.py:1780 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 66920448 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=4.73gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2023-04-05 22:47:31,747\tINFO worker.py:1553 -- Started a local Ray instance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.9.5</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 2.3.1</b></td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url=None, python_version='3.9.5', ray_version='2.3.1', ray_commit='5f14cee8dfc6d61ec4fd3bc2c440f9944e92b33a', address_info={'node_ip_address': '10.0.89.148', 'raylet_ip_address': '10.0.89.148', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2023-04-05_22-47-10_034990_451/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2023-04-05_22-47-10_034990_451/sockets/raylet', 'webui_url': None, 'session_dir': '/tmp/ray/session_2023-04-05_22-47-10_034990_451', 'metrics_export_port': 49789, 'gcs_address': '10.0.89.148:55994', 'address': '10.0.89.148:55994', 'dashboard_agent_listen_port': 52365, 'node_id': '93fbc409d28543b1b4e3e5340c6f44325b989ab6409245f75dfef2d5'})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0de9a396-5fed-4e40-a9c1-48ed280d272c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def read_file():\n",
    "    logs = open(\"/home/ray/ray_results/TorchTrainer_2023-04-05_14-32-44/TorchTrainer_672ea_00000_0_2023-04-05_14-32-45/error.txt\", \"r\").readlines()\n",
    "    print(logs)\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffe3e7f0-8890-4e32-979a-6db42e06d6af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pkg_resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cc202e8-ac36-4a58-8637-5e35a320bcd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def ray_version():\n",
    "    version = pkg_resources.get_distribution(\"ray\").version\n",
    "    print(version)\n",
    "    return version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7492598a-f587-48d3-8644-0e9da769272b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 22:24:48,578\tWARNING services.py:1780 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 66920448 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=4.84gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2023-04-05 22:24:48,701\tINFO worker.py:1544 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ray_version pid=418)\u001b[0m 2.3.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.get(ray_version.remote())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e48ba81-df8d-4171-b1c2-119c10f4df39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Failure # 1 (occurred at 2023-04-05_14-32-49)\\n',\n",
       " '\\x1b[36mray::TrainTrainable.train()\\x1b[39m (pid=1066, ip=10.0.57.80, repr=TorchTrainer)\\n',\n",
       " '  File \"/home/ray/anaconda3/lib/python3.9/site-packages/ray/tune/trainable/trainable.py\", line 347, in train\\n',\n",
       " '    result = self.step()\\n',\n",
       " '  File \"/home/ray/anaconda3/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 417, in step\\n',\n",
       " '    self._report_thread_runner_error(block=True)\\n',\n",
       " '  File \"/home/ray/anaconda3/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 589, in _report_thread_runner_error\\n',\n",
       " '    raise e\\n',\n",
       " '  File \"/home/ray/anaconda3/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 289, in run\\n',\n",
       " '    self._entrypoint()\\n',\n",
       " '  File \"/home/ray/anaconda3/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 362, in entrypoint\\n',\n",
       " '    return self._trainable_func(\\n',\n",
       " '  File \"/opt/conda/lib/python3.9/site-packages/ray/train/base_trainer.py\", line 460, in _trainable_func\\n',\n",
       " '  File \"/opt/conda/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 684, in _trainable_func\\n',\n",
       " '  File \"/opt/conda/lib/python3.9/site-packages/ray/train/base_trainer.py\", line 375, in train_func\\n',\n",
       " '  File \"/home/ray/anaconda3/lib/python3.9/site-packages/ray/train/data_parallel_trainer.py\", line 346, in training_loop\\n',\n",
       " '    backend_executor.start(initialization_hook=None)\\n',\n",
       " '  File \"/home/ray/anaconda3/lib/python3.9/site-packages/ray/train/_internal/backend_executor.py\", line 126, in start\\n',\n",
       " '    self._backend.on_start(self.worker_group, self._backend_config)\\n',\n",
       " '  File \"/home/ray/anaconda3/lib/python3.9/site-packages/ray/train/torch/config.py\", line 152, in on_start\\n',\n",
       " '    ray.get(setup_futures)\\n',\n",
       " 'ray.exceptions.RayTaskError(RuntimeError): \\x1b[36mray::RayTrainWorker._RayTrainWorker__execute()\\x1b[39m (pid=1095, ip=10.0.57.80, repr=<ray.train._internal.worker_group.RayTrainWorker object at 0x7fcdb90dbf10>)\\n',\n",
       " '  File \"/home/ray/anaconda3/lib/python3.9/site-packages/ray/train/_internal/worker_group.py\", line 26, in __execute\\n',\n",
       " '    return func(*args, **kwargs)\\n',\n",
       " '  File \"/home/ray/anaconda3/lib/python3.9/site-packages/ray/train/torch/config.py\", line 89, in _setup_torch_process_group\\n',\n",
       " '    dist.init_process_group(\\n',\n",
       " '  File \"/home/ray/anaconda3/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py\", line 500, in init_process_group\\n',\n",
       " '    store, rank, world_size = next(rendezvous_iterator)\\n',\n",
       " '  File \"/home/ray/anaconda3/lib/python3.9/site-packages/torch/distributed/rendezvous.py\", line 190, in _env_rendezvous_handler\\n',\n",
       " '    store = TCPStore(master_addr, master_port, world_size, start_daemon, timeout)\\n',\n",
       " 'RuntimeError: Connection reset by peer\\n']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(read_file pid=6316)\u001b[0m ['Failure # 1 (occurred at 2023-04-05_14-32-49)\\n', '\\x1b[36mray::TrainTrainable.train()\\x1b[39m (pid=1066, ip=10.0.57.80, repr=TorchTrainer)\\n', '  File \"/home/ray/anaconda3/lib/python3.9/site-packages/ray/tune/trainable/trainable.py\", line 347, in train\\n', '    result = self.step()\\n', '  File \"/home/ray/anaconda3/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 417, in step\\n', '    self._report_thread_runner_error(block=True)\\n', '  File \"/home/ray/anaconda3/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 589, in _report_thread_runner_error\\n', '    raise e\\n', '  File \"/home/ray/anaconda3/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 289, in run\\n', '    self._entrypoint()\\n', '  File \"/home/ray/anaconda3/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 362, in entrypoint\\n', '    return self._trainable_func(\\n', '  File \"/opt/conda/lib/python3.9/site-packages/ray/train/base_trainer.py\", line 460, in _trainable_func\\n', '  File \"/opt/conda/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 684, in _trainable_func\\n', '  File \"/opt/conda/lib/python3.9/site-packages/ray/train/base_trainer.py\", line 375, in train_func\\n', '  File \"/home/ray/anaconda3/lib/python3.9/site-packages/ray/train/data_parallel_trainer.py\", line 346, in training_loop\\n', '    backend_executor.start(initialization_hook=None)\\n', '  File \"/home/ray/anaconda3/lib/python3.9/site-packages/ray/train/_internal/backend_executor.py\", line 126, in start\\n', '    self._backend.on_start(self.worker_group, self._backend_config)\\n', '  File \"/home/ray/anaconda3/lib/python3.9/site-packages/ray/train/torch/config.py\", line 152, in on_start\\n', '    ray.get(setup_futures)\\n', 'ray.exceptions.RayTaskError(RuntimeError): \\x1b[36mray::RayTrainWorker._RayTrainWorker__execute()\\x1b[39m (pid=1095, ip=10.0.57.80, repr=<ray.train._internal.worker_group.RayTrainWorker object at 0x7fcdb90dbf10>)\\n', '  File \"/home/ray/anaconda3/lib/python3.9/site-packages/ray/train/_internal/worker_group.py\", line 26, in __execute\\n', '    return func(*args, **kwargs)\\n', '  File \"/home/ray/anaconda3/lib/python3.9/site-packages/ray/train/torch/config.py\", line 89, in _setup_torch_process_group\\n', '    dist.init_process_group(\\n', '  File \"/home/ray/anaconda3/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py\", line 500, in init_process_group\\n', '    store, rank, world_size = next(rendezvous_iterator)\\n', '  File \"/home/ray/anaconda3/lib/python3.9/site-packages/torch/distributed/rendezvous.py\", line 190, in _env_rendezvous_handler\\n', '    store = TCPStore(master_addr, master_port, world_size, start_daemon, timeout)\\n', 'RuntimeError: Connection reset by peer\\n']\n"
     ]
    }
   ],
   "source": [
    "ray.get(read_file.remote())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2980d017-e64a-4e7a-940c-ea63b3a11336",
   "metadata": {},
   "outputs": [],
   "source": [
    "'scikit-image' : pkg_resources.get_distribution(\"scikit-image\").version,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f806f87-9607-41c5-a021-1cb1008054b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ray\n",
    "ray.__version__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
